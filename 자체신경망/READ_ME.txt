### 1. multi_layer_net.py (신경망 엔진)

* **역할:** `two_layer_net.py` 코드를 일반화(Generalize)한 파일입니다.
* **기능:** `[100, 50]`처럼 리스트를 입력받아, 2층, 3층 등 N개의 층을 가진 신경망을 동적으로 생성하는 **핵심 클래스**입니다.

---

### 2. final_find_best_neuralnet.py (R&D 연구소 / 탐색기)

* **역할:** **최적의 하이퍼파라미터(lr, hs)를 찾는 'R&D 연구소'**입니다.
* **기능:**
    1.  `x_train` (훈련용) / `x_val` (검증용) 데이터를 사용합니다.
    2.  **2단계 최적화 전략**을 사용합니다:
        * **1단계 (넓은 탐색):** `lr` (0.0001~0.5), `hs` (20~150) 같은 넓은 범위에서 무작위(랜덤 서치)로 테스트하여 "대박"이 날 가능성이 높은 **최적의 *범위***를 찾습니다.
        * **2단계 (정밀 탐색):** 1단계에서 찾은 "대박" 범위 (예: `lr` 0.01~0.08, `hs` 70~95) 안에서만 촘촘하게(그리드 서치) 다시 테스트하여 **최종 근사값**을 찾습니다.
* **상태:** 현재 2층 신경망(`[hs]`)을 기준으로 최적의 `lr`과 `hs` 1개를 찾도록 구현되어 있습니다. (향후 3층+ 확장 논의)

---

### 3. train_neuralnet.py (메인 팩토리 / 최종 훈련기)

* **역할:** **'최종 모델'을 훈련시키고 성능을 평가하는 '메인 팩토리'**입니다.
* **기능:**
    1.  `final_find_best_neuralnet.py` (R&D 연구소)에서 찾은 **최적의 `lr`과 `hs` 값을 이 파일에 직접 입력**합니다.
    2.  **모든 훈련 데이터(60,000개)**를 사용하여 모델을 최대 성능으로 훈련시킵니다.
    3.  **`x_test` (실제 시험지)**를 사용해 모델의 **최종 성능(정확도)**을 평가합니다.

---

### 📋 작업 순서 (Workflow)

1.  **`final_find_best_neuralnet.py`**를 실행해서 최적의 `lr`과 `hs` 값을 찾습니다.
    * (예: `lr=0.303...`, `hs=93` 확인)
2.  **`train_neuralnet.py`** 파일을 엽니다.
3.  1번에서 찾은 `lr`과 `hs` 값을 `train_neuralnet.py` 상단의 하이퍼파라미터 변수에 **수동으로 덮어씁니다.**
4.  **`train_neuralnet.py`**를 실행하여 **최종 정확도**를 확인합니다.



train_neuralnet : 추가수정 예정(그래프 등등)
multi_layer_net :  two_layer_net 을 다중(2층 이상) 신경망 전용으로 수정
final_find_best_neuralnet : 추가 수정예정 / 최적의 lr와 hs를 구하는 코드